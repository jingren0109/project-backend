{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "loans = joblib.load(\"../data/final_model_data.joblib\")\n",
    "\n",
    "# import pandas as pd\n",
    "#\n",
    "# # Convert the issue_d column to a datetime object\n",
    "# loans['issue_d'] = pd.to_datetime(loans['issue_d'])\n",
    "#\n",
    "# # Create a boolean mask for rows with issue_d in 2018\n",
    "# mask = loans['issue_d'].dt.year == 2018\n",
    "#\n",
    "# # Filter the data using the mask\n",
    "# loans = loans[mask]\n",
    "\n",
    "loans = loans.head(10000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 71)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set contains 2,000 loans.\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(loans, test_size=0.2, shuffle=False)\n",
    "train, test = train.copy(), test.copy()\n",
    "print(f\"The test set contains {len(test):,} loans.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "onehot_cols = [\"term\", \"application_type\", \"home_ownership\", \"purpose\"]\n",
    "ordinal_cols = {\n",
    "    \"emp_length\": [\n",
    "        \"< 1 year\",\n",
    "        \"1 year\",\n",
    "        \"2 years\",\n",
    "        \"3 years\",\n",
    "        \"4 years\",\n",
    "        \"5 years\",\n",
    "        \"6 years\",\n",
    "        \"7 years\",\n",
    "        \"8 years\",\n",
    "        \"9 years\",\n",
    "        \"10+ years\",\n",
    "    ],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def run_pipeline_cv_nn(\n",
    "    data,\n",
    "    onehot_cols,\n",
    "    ordinal_cols,\n",
    "    batch_size,\n",
    "):\n",
    "    X = data.drop(columns=[\"issue_d\", \"date\", \"grade\", \"grade_encoded\", \"sub_grade\", \"recovered_percentage\", \"expected_return\"])\n",
    "    y = data[\"grade_encoded\"]\n",
    "\n",
    "    transformer = DataFrameMapper(\n",
    "        [\n",
    "            (onehot_cols, OneHotEncoder(drop=\"if_binary\", handle_unknown=\"error\")),\n",
    "            (\n",
    "                list(ordinal_cols.keys()),\n",
    "                OrdinalEncoder(categories=list(ordinal_cols.values())),\n",
    "            ),\n",
    "        ],\n",
    "        default=StandardScaler(),\n",
    "    )\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    history_list = []\n",
    "    model_list = []\n",
    "    transformer_list = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        print(X_train.keys())\n",
    "        X_train = transformer.fit_transform(X_train)\n",
    "        X_valid = transformer.transform(X_valid)\n",
    "\n",
    "        input_nodes = X_train.shape[1]\n",
    "\n",
    "        # Define the model architecture\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=input_nodes))\n",
    "        model.add(Dense(64, activation=\"relu\"))\n",
    "        model.add(Dropout(0.3, seed=0))\n",
    "        model.add(Dense(32, activation=\"relu\"))\n",
    "        model.add(Dropout(0.3, seed=1))\n",
    "        model.add(Dense(16, activation=\"relu\"))\n",
    "        model.add(Dropout(0.3, seed=2))\n",
    "        model.add(Dense(7, activation=\"softmax\"))\n",
    "        model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "        # Define the EarlyStopping callback\n",
    "        early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=100,\n",
    "            validation_data=(X_valid, y_valid),\n",
    "            verbose=2,\n",
    "            callbacks=[early_stopping],  # Add the EarlyStopping callback\n",
    "        )\n",
    "\n",
    "        history_list.append(history.history)\n",
    "        model_list.append(model)\n",
    "        transformer_list.append(transformer)\n",
    "\n",
    "    return history_list, model_list, transformer_list\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_amnt', 'term', 'emp_length', 'home_ownership', 'annual_inc',\n",
      "       'purpose', 'dti', 'delinq_2yrs', 'cr_hist_age_mths', 'fico_range_low',\n",
      "       'fico_range_high', 'inq_last_6mths', 'inv_mths_since_last_delinq',\n",
      "       'inv_mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n",
      "       'revol_util', 'total_acc', 'collections_12_mths_ex_med',\n",
      "       'inv_mths_since_last_major_derog', 'application_type',\n",
      "       'annual_inc_joint', 'dti_joint', 'acc_now_delinq', 'tot_coll_amt',\n",
      "       'tot_cur_bal', 'total_rev_hi_lim', 'acc_open_past_24mths',\n",
      "       'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths',\n",
      "       'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op',\n",
      "       'inv_mo_sin_rcnt_rev_tl_op', 'inv_mo_sin_rcnt_tl', 'mort_acc',\n",
      "       'inv_mths_since_recent_bc', 'inv_mths_since_recent_bc_dlq',\n",
      "       'inv_mths_since_recent_inq', 'inv_mths_since_recent_revol_delinq',\n",
      "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
      "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
      "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
      "       'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
      "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
      "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
      "       'total_il_high_credit_limit'],\n",
      "      dtype='object')\n",
      "Epoch 1/100\n",
      "50/50 - 1s - loss: 1.9058 - accuracy: 0.1978 - val_loss: 1.6210 - val_accuracy: 0.3844 - 1s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "50/50 - 0s - loss: 1.6364 - accuracy: 0.3345 - val_loss: 1.4192 - val_accuracy: 0.4394 - 94ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "50/50 - 0s - loss: 1.4857 - accuracy: 0.3841 - val_loss: 1.2825 - val_accuracy: 0.5031 - 95ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "50/50 - 0s - loss: 1.3753 - accuracy: 0.4327 - val_loss: 1.1770 - val_accuracy: 0.5400 - 97ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "50/50 - 0s - loss: 1.2763 - accuracy: 0.4567 - val_loss: 1.0889 - val_accuracy: 0.5569 - 93ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "50/50 - 0s - loss: 1.1987 - accuracy: 0.4853 - val_loss: 1.0092 - val_accuracy: 0.5856 - 100ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "50/50 - 0s - loss: 1.1259 - accuracy: 0.5283 - val_loss: 0.9496 - val_accuracy: 0.5987 - 93ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "50/50 - 0s - loss: 1.0660 - accuracy: 0.5447 - val_loss: 0.8943 - val_accuracy: 0.6175 - 90ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "50/50 - 0s - loss: 1.0335 - accuracy: 0.5581 - val_loss: 0.8713 - val_accuracy: 0.6288 - 116ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "50/50 - 0s - loss: 1.0070 - accuracy: 0.5759 - val_loss: 0.8350 - val_accuracy: 0.6575 - 122ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "50/50 - 0s - loss: 0.9900 - accuracy: 0.5825 - val_loss: 0.8111 - val_accuracy: 0.6750 - 117ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "50/50 - 0s - loss: 0.9542 - accuracy: 0.5981 - val_loss: 0.7782 - val_accuracy: 0.7094 - 94ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "50/50 - 0s - loss: 0.9278 - accuracy: 0.6055 - val_loss: 0.7490 - val_accuracy: 0.7081 - 93ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "50/50 - 0s - loss: 0.8981 - accuracy: 0.6186 - val_loss: 0.7366 - val_accuracy: 0.7200 - 105ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "50/50 - 0s - loss: 0.8865 - accuracy: 0.6194 - val_loss: 0.7132 - val_accuracy: 0.7312 - 99ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "50/50 - 0s - loss: 0.8665 - accuracy: 0.6266 - val_loss: 0.6963 - val_accuracy: 0.7350 - 100ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "50/50 - 0s - loss: 0.8387 - accuracy: 0.6475 - val_loss: 0.6832 - val_accuracy: 0.7419 - 96ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "50/50 - 0s - loss: 0.8292 - accuracy: 0.6466 - val_loss: 0.6683 - val_accuracy: 0.7500 - 97ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "50/50 - 0s - loss: 0.8200 - accuracy: 0.6516 - val_loss: 0.6688 - val_accuracy: 0.7344 - 104ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "50/50 - 0s - loss: 0.8031 - accuracy: 0.6592 - val_loss: 0.6572 - val_accuracy: 0.7500 - 96ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "50/50 - 0s - loss: 0.7932 - accuracy: 0.6708 - val_loss: 0.6514 - val_accuracy: 0.7462 - 98ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "50/50 - 0s - loss: 0.7726 - accuracy: 0.6731 - val_loss: 0.6347 - val_accuracy: 0.7575 - 103ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "50/50 - 0s - loss: 0.7540 - accuracy: 0.6830 - val_loss: 0.6251 - val_accuracy: 0.7594 - 98ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "50/50 - 0s - loss: 0.7609 - accuracy: 0.6906 - val_loss: 0.6238 - val_accuracy: 0.7600 - 143ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "50/50 - 0s - loss: 0.7514 - accuracy: 0.6866 - val_loss: 0.6174 - val_accuracy: 0.7575 - 101ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "50/50 - 0s - loss: 0.7318 - accuracy: 0.6936 - val_loss: 0.5990 - val_accuracy: 0.7638 - 110ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "50/50 - 0s - loss: 0.7220 - accuracy: 0.6986 - val_loss: 0.5988 - val_accuracy: 0.7625 - 109ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "50/50 - 0s - loss: 0.7160 - accuracy: 0.7016 - val_loss: 0.5872 - val_accuracy: 0.7638 - 112ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "50/50 - 0s - loss: 0.7095 - accuracy: 0.7123 - val_loss: 0.5934 - val_accuracy: 0.7675 - 99ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "50/50 - 0s - loss: 0.7013 - accuracy: 0.7128 - val_loss: 0.5853 - val_accuracy: 0.7669 - 94ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "50/50 - 0s - loss: 0.6975 - accuracy: 0.7111 - val_loss: 0.5844 - val_accuracy: 0.7756 - 94ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "50/50 - 0s - loss: 0.6802 - accuracy: 0.7181 - val_loss: 0.5733 - val_accuracy: 0.7613 - 97ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "50/50 - 0s - loss: 0.6798 - accuracy: 0.7255 - val_loss: 0.5722 - val_accuracy: 0.7625 - 99ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "50/50 - 0s - loss: 0.6718 - accuracy: 0.7253 - val_loss: 0.5674 - val_accuracy: 0.7644 - 91ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "50/50 - 0s - loss: 0.6698 - accuracy: 0.7250 - val_loss: 0.5805 - val_accuracy: 0.7613 - 90ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "50/50 - 0s - loss: 0.6560 - accuracy: 0.7316 - val_loss: 0.5685 - val_accuracy: 0.7713 - 90ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "50/50 - 0s - loss: 0.6541 - accuracy: 0.7295 - val_loss: 0.5558 - val_accuracy: 0.7738 - 93ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "50/50 - 0s - loss: 0.6376 - accuracy: 0.7394 - val_loss: 0.5658 - val_accuracy: 0.7750 - 102ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "50/50 - 0s - loss: 0.6472 - accuracy: 0.7364 - val_loss: 0.5683 - val_accuracy: 0.7700 - 93ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "50/50 - 0s - loss: 0.6356 - accuracy: 0.7361 - val_loss: 0.5594 - val_accuracy: 0.7744 - 92ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "50/50 - 0s - loss: 0.6498 - accuracy: 0.7425 - val_loss: 0.5523 - val_accuracy: 0.7806 - 97ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "50/50 - 0s - loss: 0.6310 - accuracy: 0.7484 - val_loss: 0.5527 - val_accuracy: 0.7788 - 98ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "50/50 - 0s - loss: 0.6417 - accuracy: 0.7402 - val_loss: 0.5534 - val_accuracy: 0.7794 - 99ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "50/50 - 0s - loss: 0.6152 - accuracy: 0.7475 - val_loss: 0.5500 - val_accuracy: 0.7788 - 110ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "50/50 - 0s - loss: 0.6075 - accuracy: 0.7531 - val_loss: 0.5429 - val_accuracy: 0.7837 - 99ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "50/50 - 0s - loss: 0.6208 - accuracy: 0.7558 - val_loss: 0.5443 - val_accuracy: 0.7744 - 94ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "50/50 - 0s - loss: 0.6137 - accuracy: 0.7539 - val_loss: 0.5405 - val_accuracy: 0.7775 - 102ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "50/50 - 0s - loss: 0.6051 - accuracy: 0.7605 - val_loss: 0.5485 - val_accuracy: 0.7788 - 106ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "50/50 - 0s - loss: 0.6047 - accuracy: 0.7613 - val_loss: 0.5384 - val_accuracy: 0.7900 - 96ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "50/50 - 0s - loss: 0.6086 - accuracy: 0.7517 - val_loss: 0.5373 - val_accuracy: 0.7862 - 93ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "50/50 - 0s - loss: 0.6050 - accuracy: 0.7570 - val_loss: 0.5457 - val_accuracy: 0.7831 - 91ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "50/50 - 0s - loss: 0.5888 - accuracy: 0.7634 - val_loss: 0.5229 - val_accuracy: 0.7969 - 95ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "50/50 - 0s - loss: 0.5915 - accuracy: 0.7584 - val_loss: 0.5356 - val_accuracy: 0.7756 - 99ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "50/50 - 0s - loss: 0.6002 - accuracy: 0.7570 - val_loss: 0.5430 - val_accuracy: 0.7769 - 97ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "50/50 - 0s - loss: 0.5881 - accuracy: 0.7570 - val_loss: 0.5422 - val_accuracy: 0.7806 - 139ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "50/50 - 0s - loss: 0.5880 - accuracy: 0.7592 - val_loss: 0.5278 - val_accuracy: 0.7862 - 91ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "50/50 - 0s - loss: 0.5731 - accuracy: 0.7741 - val_loss: 0.5225 - val_accuracy: 0.8019 - 98ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "50/50 - 0s - loss: 0.5695 - accuracy: 0.7642 - val_loss: 0.5287 - val_accuracy: 0.7881 - 108ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "50/50 - 0s - loss: 0.5615 - accuracy: 0.7745 - val_loss: 0.5258 - val_accuracy: 0.8012 - 98ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "50/50 - 0s - loss: 0.5752 - accuracy: 0.7684 - val_loss: 0.5292 - val_accuracy: 0.7987 - 111ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "50/50 - 0s - loss: 0.5633 - accuracy: 0.7750 - val_loss: 0.5258 - val_accuracy: 0.7981 - 120ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "50/50 - 0s - loss: 0.5560 - accuracy: 0.7742 - val_loss: 0.5189 - val_accuracy: 0.7856 - 112ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "50/50 - 0s - loss: 0.5635 - accuracy: 0.7709 - val_loss: 0.5184 - val_accuracy: 0.7869 - 96ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "50/50 - 0s - loss: 0.5696 - accuracy: 0.7747 - val_loss: 0.5146 - val_accuracy: 0.7881 - 94ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "50/50 - 0s - loss: 0.5557 - accuracy: 0.7759 - val_loss: 0.5146 - val_accuracy: 0.7906 - 94ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "50/50 - 0s - loss: 0.5570 - accuracy: 0.7798 - val_loss: 0.5170 - val_accuracy: 0.7837 - 100ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "50/50 - 0s - loss: 0.5508 - accuracy: 0.7800 - val_loss: 0.5196 - val_accuracy: 0.7950 - 92ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "50/50 - 0s - loss: 0.5487 - accuracy: 0.7786 - val_loss: 0.5161 - val_accuracy: 0.8012 - 98ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "50/50 - 0s - loss: 0.5510 - accuracy: 0.7784 - val_loss: 0.5296 - val_accuracy: 0.7919 - 95ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "50/50 - 0s - loss: 0.5463 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7987 - 98ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "50/50 - 0s - loss: 0.5388 - accuracy: 0.7841 - val_loss: 0.5088 - val_accuracy: 0.7894 - 94ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "50/50 - 0s - loss: 0.5432 - accuracy: 0.7841 - val_loss: 0.5246 - val_accuracy: 0.8019 - 93ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "50/50 - 0s - loss: 0.5419 - accuracy: 0.7892 - val_loss: 0.5124 - val_accuracy: 0.7969 - 105ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "50/50 - 0s - loss: 0.5190 - accuracy: 0.7898 - val_loss: 0.5032 - val_accuracy: 0.7844 - 93ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "50/50 - 0s - loss: 0.5282 - accuracy: 0.7941 - val_loss: 0.5035 - val_accuracy: 0.7950 - 97ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "50/50 - 0s - loss: 0.5221 - accuracy: 0.7872 - val_loss: 0.5179 - val_accuracy: 0.7900 - 95ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "50/50 - 0s - loss: 0.5235 - accuracy: 0.7914 - val_loss: 0.5091 - val_accuracy: 0.7875 - 93ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "50/50 - 0s - loss: 0.5162 - accuracy: 0.7927 - val_loss: 0.5126 - val_accuracy: 0.7962 - 103ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "50/50 - 0s - loss: 0.5211 - accuracy: 0.7975 - val_loss: 0.5086 - val_accuracy: 0.7850 - 98ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "50/50 - 0s - loss: 0.5270 - accuracy: 0.7983 - val_loss: 0.5072 - val_accuracy: 0.8019 - 97ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "50/50 - 0s - loss: 0.5063 - accuracy: 0.7917 - val_loss: 0.5154 - val_accuracy: 0.7925 - 93ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "50/50 - 0s - loss: 0.5213 - accuracy: 0.7944 - val_loss: 0.5121 - val_accuracy: 0.7887 - 93ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "50/50 - 0s - loss: 0.5098 - accuracy: 0.8011 - val_loss: 0.5080 - val_accuracy: 0.7887 - 107ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "50/50 - 0s - loss: 0.5213 - accuracy: 0.7897 - val_loss: 0.5029 - val_accuracy: 0.8019 - 93ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "50/50 - 0s - loss: 0.5145 - accuracy: 0.7983 - val_loss: 0.5060 - val_accuracy: 0.7950 - 92ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "50/50 - 0s - loss: 0.5076 - accuracy: 0.8037 - val_loss: 0.5068 - val_accuracy: 0.7994 - 92ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "50/50 - 0s - loss: 0.5052 - accuracy: 0.7964 - val_loss: 0.5019 - val_accuracy: 0.7844 - 95ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "50/50 - 0s - loss: 0.5058 - accuracy: 0.8034 - val_loss: 0.5071 - val_accuracy: 0.7925 - 100ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "50/50 - 0s - loss: 0.5149 - accuracy: 0.8008 - val_loss: 0.5031 - val_accuracy: 0.7956 - 90ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "50/50 - 0s - loss: 0.4980 - accuracy: 0.8072 - val_loss: 0.5051 - val_accuracy: 0.7862 - 97ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "50/50 - 0s - loss: 0.4903 - accuracy: 0.8081 - val_loss: 0.5028 - val_accuracy: 0.7919 - 95ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "50/50 - 0s - loss: 0.4967 - accuracy: 0.8069 - val_loss: 0.4980 - val_accuracy: 0.8037 - 98ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "50/50 - 0s - loss: 0.4890 - accuracy: 0.8066 - val_loss: 0.5114 - val_accuracy: 0.7844 - 100ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "50/50 - 0s - loss: 0.4842 - accuracy: 0.8100 - val_loss: 0.5017 - val_accuracy: 0.7956 - 96ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "50/50 - 0s - loss: 0.4947 - accuracy: 0.8084 - val_loss: 0.5002 - val_accuracy: 0.7987 - 91ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "50/50 - 0s - loss: 0.4682 - accuracy: 0.8066 - val_loss: 0.5117 - val_accuracy: 0.7875 - 92ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "50/50 - 0s - loss: 0.5025 - accuracy: 0.8000 - val_loss: 0.4983 - val_accuracy: 0.8000 - 95ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "50/50 - 0s - loss: 0.5009 - accuracy: 0.8030 - val_loss: 0.4956 - val_accuracy: 0.8006 - 100ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "50/50 - 0s - loss: 0.4884 - accuracy: 0.8086 - val_loss: 0.4955 - val_accuracy: 0.7994 - 98ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "50/50 - 0s - loss: 0.4913 - accuracy: 0.8075 - val_loss: 0.5061 - val_accuracy: 0.7856 - 99ms/epoch - 2ms/step\n",
      "Index(['loan_amnt', 'term', 'emp_length', 'home_ownership', 'annual_inc',\n",
      "       'purpose', 'dti', 'delinq_2yrs', 'cr_hist_age_mths', 'fico_range_low',\n",
      "       'fico_range_high', 'inq_last_6mths', 'inv_mths_since_last_delinq',\n",
      "       'inv_mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n",
      "       'revol_util', 'total_acc', 'collections_12_mths_ex_med',\n",
      "       'inv_mths_since_last_major_derog', 'application_type',\n",
      "       'annual_inc_joint', 'dti_joint', 'acc_now_delinq', 'tot_coll_amt',\n",
      "       'tot_cur_bal', 'total_rev_hi_lim', 'acc_open_past_24mths',\n",
      "       'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths',\n",
      "       'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op',\n",
      "       'inv_mo_sin_rcnt_rev_tl_op', 'inv_mo_sin_rcnt_tl', 'mort_acc',\n",
      "       'inv_mths_since_recent_bc', 'inv_mths_since_recent_bc_dlq',\n",
      "       'inv_mths_since_recent_inq', 'inv_mths_since_recent_revol_delinq',\n",
      "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
      "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
      "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
      "       'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
      "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
      "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
      "       'total_il_high_credit_limit'],\n",
      "      dtype='object')\n",
      "Epoch 1/100\n",
      "50/50 - 1s - loss: 1.8872 - accuracy: 0.2450 - val_loss: 1.7222 - val_accuracy: 0.3300 - 956ms/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "50/50 - 0s - loss: 1.7005 - accuracy: 0.3244 - val_loss: 1.5645 - val_accuracy: 0.4181 - 101ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "50/50 - 0s - loss: 1.6098 - accuracy: 0.3486 - val_loss: 1.4443 - val_accuracy: 0.4369 - 101ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "50/50 - 0s - loss: 1.5109 - accuracy: 0.3959 - val_loss: 1.3295 - val_accuracy: 0.4625 - 94ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "50/50 - 0s - loss: 1.4231 - accuracy: 0.4208 - val_loss: 1.2254 - val_accuracy: 0.4844 - 98ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "50/50 - 0s - loss: 1.3253 - accuracy: 0.4502 - val_loss: 1.1042 - val_accuracy: 0.5500 - 96ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "50/50 - 0s - loss: 1.2468 - accuracy: 0.4836 - val_loss: 1.0127 - val_accuracy: 0.6062 - 102ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "50/50 - 0s - loss: 1.1633 - accuracy: 0.5222 - val_loss: 0.9301 - val_accuracy: 0.6463 - 97ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "50/50 - 0s - loss: 1.0986 - accuracy: 0.5409 - val_loss: 0.8631 - val_accuracy: 0.6600 - 93ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "50/50 - 0s - loss: 1.0519 - accuracy: 0.5631 - val_loss: 0.8246 - val_accuracy: 0.6719 - 91ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "50/50 - 0s - loss: 0.9962 - accuracy: 0.5834 - val_loss: 0.7658 - val_accuracy: 0.7013 - 92ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "50/50 - 0s - loss: 0.9616 - accuracy: 0.6086 - val_loss: 0.7394 - val_accuracy: 0.7262 - 95ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "50/50 - 0s - loss: 0.9241 - accuracy: 0.6194 - val_loss: 0.7142 - val_accuracy: 0.7250 - 97ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "50/50 - 0s - loss: 0.8904 - accuracy: 0.6284 - val_loss: 0.6886 - val_accuracy: 0.7344 - 101ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "50/50 - 0s - loss: 0.8622 - accuracy: 0.6361 - val_loss: 0.6631 - val_accuracy: 0.7431 - 94ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "50/50 - 0s - loss: 0.8433 - accuracy: 0.6477 - val_loss: 0.6559 - val_accuracy: 0.7394 - 97ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "50/50 - 0s - loss: 0.8172 - accuracy: 0.6633 - val_loss: 0.6436 - val_accuracy: 0.7394 - 94ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "50/50 - 0s - loss: 0.7995 - accuracy: 0.6633 - val_loss: 0.6229 - val_accuracy: 0.7494 - 93ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "50/50 - 0s - loss: 0.7931 - accuracy: 0.6691 - val_loss: 0.6285 - val_accuracy: 0.7400 - 107ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "50/50 - 0s - loss: 0.7695 - accuracy: 0.6850 - val_loss: 0.6190 - val_accuracy: 0.7519 - 95ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "50/50 - 0s - loss: 0.7576 - accuracy: 0.6842 - val_loss: 0.6043 - val_accuracy: 0.7513 - 96ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "50/50 - 0s - loss: 0.7577 - accuracy: 0.6867 - val_loss: 0.5910 - val_accuracy: 0.7575 - 94ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "50/50 - 0s - loss: 0.7335 - accuracy: 0.6998 - val_loss: 0.5845 - val_accuracy: 0.7725 - 94ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "50/50 - 0s - loss: 0.7227 - accuracy: 0.6984 - val_loss: 0.5764 - val_accuracy: 0.7594 - 110ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "50/50 - 0s - loss: 0.7316 - accuracy: 0.7016 - val_loss: 0.5857 - val_accuracy: 0.7556 - 91ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "50/50 - 0s - loss: 0.6921 - accuracy: 0.7172 - val_loss: 0.5792 - val_accuracy: 0.7613 - 94ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "50/50 - 0s - loss: 0.7042 - accuracy: 0.7141 - val_loss: 0.5610 - val_accuracy: 0.7694 - 92ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "50/50 - 0s - loss: 0.6690 - accuracy: 0.7216 - val_loss: 0.5553 - val_accuracy: 0.7681 - 93ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "50/50 - 0s - loss: 0.6741 - accuracy: 0.7275 - val_loss: 0.5451 - val_accuracy: 0.7750 - 108ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "50/50 - 0s - loss: 0.6791 - accuracy: 0.7194 - val_loss: 0.5489 - val_accuracy: 0.7850 - 94ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "50/50 - 0s - loss: 0.6630 - accuracy: 0.7275 - val_loss: 0.5375 - val_accuracy: 0.7819 - 98ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "50/50 - 0s - loss: 0.6597 - accuracy: 0.7320 - val_loss: 0.5309 - val_accuracy: 0.7744 - 94ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "50/50 - 0s - loss: 0.6420 - accuracy: 0.7389 - val_loss: 0.5270 - val_accuracy: 0.7788 - 93ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "50/50 - 0s - loss: 0.6387 - accuracy: 0.7325 - val_loss: 0.5174 - val_accuracy: 0.7775 - 109ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "50/50 - 0s - loss: 0.6333 - accuracy: 0.7369 - val_loss: 0.5254 - val_accuracy: 0.7837 - 97ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "50/50 - 0s - loss: 0.6192 - accuracy: 0.7464 - val_loss: 0.5154 - val_accuracy: 0.7900 - 104ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "50/50 - 0s - loss: 0.6254 - accuracy: 0.7489 - val_loss: 0.5096 - val_accuracy: 0.7881 - 101ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "50/50 - 0s - loss: 0.6092 - accuracy: 0.7502 - val_loss: 0.5107 - val_accuracy: 0.7856 - 97ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "50/50 - 0s - loss: 0.6185 - accuracy: 0.7506 - val_loss: 0.5123 - val_accuracy: 0.7831 - 116ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "50/50 - 0s - loss: 0.6131 - accuracy: 0.7520 - val_loss: 0.5071 - val_accuracy: 0.7987 - 100ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "50/50 - 0s - loss: 0.6067 - accuracy: 0.7594 - val_loss: 0.5071 - val_accuracy: 0.7969 - 94ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "50/50 - 0s - loss: 0.5896 - accuracy: 0.7584 - val_loss: 0.5031 - val_accuracy: 0.7931 - 97ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "50/50 - 0s - loss: 0.6009 - accuracy: 0.7634 - val_loss: 0.5037 - val_accuracy: 0.7794 - 91ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "50/50 - 0s - loss: 0.5938 - accuracy: 0.7569 - val_loss: 0.4910 - val_accuracy: 0.7925 - 99ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "50/50 - 0s - loss: 0.5860 - accuracy: 0.7684 - val_loss: 0.4935 - val_accuracy: 0.7906 - 91ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "50/50 - 0s - loss: 0.5908 - accuracy: 0.7611 - val_loss: 0.4963 - val_accuracy: 0.8050 - 97ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "50/50 - 0s - loss: 0.5796 - accuracy: 0.7772 - val_loss: 0.4996 - val_accuracy: 0.7937 - 95ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "50/50 - 0s - loss: 0.5801 - accuracy: 0.7669 - val_loss: 0.4865 - val_accuracy: 0.7887 - 98ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "50/50 - 0s - loss: 0.5737 - accuracy: 0.7727 - val_loss: 0.4807 - val_accuracy: 0.7969 - 109ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "50/50 - 0s - loss: 0.5661 - accuracy: 0.7781 - val_loss: 0.4819 - val_accuracy: 0.8056 - 96ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "50/50 - 0s - loss: 0.5615 - accuracy: 0.7783 - val_loss: 0.4822 - val_accuracy: 0.8087 - 94ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "50/50 - 0s - loss: 0.5612 - accuracy: 0.7730 - val_loss: 0.4902 - val_accuracy: 0.8012 - 93ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "50/50 - 0s - loss: 0.5468 - accuracy: 0.7808 - val_loss: 0.4706 - val_accuracy: 0.7925 - 96ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "50/50 - 0s - loss: 0.5730 - accuracy: 0.7666 - val_loss: 0.4840 - val_accuracy: 0.7900 - 102ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "50/50 - 0s - loss: 0.5489 - accuracy: 0.7791 - val_loss: 0.4755 - val_accuracy: 0.8156 - 96ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "50/50 - 0s - loss: 0.5515 - accuracy: 0.7780 - val_loss: 0.4769 - val_accuracy: 0.7900 - 98ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "50/50 - 0s - loss: 0.5443 - accuracy: 0.7830 - val_loss: 0.4721 - val_accuracy: 0.8087 - 97ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "50/50 - 0s - loss: 0.5502 - accuracy: 0.7841 - val_loss: 0.4790 - val_accuracy: 0.7987 - 95ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "50/50 - 0s - loss: 0.5388 - accuracy: 0.7886 - val_loss: 0.4711 - val_accuracy: 0.8081 - 105ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "50/50 - 0s - loss: 0.5334 - accuracy: 0.7836 - val_loss: 0.4716 - val_accuracy: 0.7944 - 93ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "50/50 - 0s - loss: 0.5467 - accuracy: 0.7806 - val_loss: 0.4709 - val_accuracy: 0.7969 - 91ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "50/50 - 0s - loss: 0.5476 - accuracy: 0.7777 - val_loss: 0.4746 - val_accuracy: 0.7994 - 91ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "50/50 - 0s - loss: 0.5201 - accuracy: 0.7992 - val_loss: 0.4669 - val_accuracy: 0.8131 - 98ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "50/50 - 0s - loss: 0.5321 - accuracy: 0.8000 - val_loss: 0.4548 - val_accuracy: 0.8175 - 103ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "50/50 - 0s - loss: 0.5219 - accuracy: 0.7978 - val_loss: 0.4553 - val_accuracy: 0.8125 - 95ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "50/50 - 0s - loss: 0.5186 - accuracy: 0.7947 - val_loss: 0.4675 - val_accuracy: 0.8031 - 96ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "50/50 - 0s - loss: 0.5175 - accuracy: 0.7966 - val_loss: 0.4649 - val_accuracy: 0.8081 - 94ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "50/50 - 0s - loss: 0.5178 - accuracy: 0.8002 - val_loss: 0.4578 - val_accuracy: 0.8050 - 90ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "50/50 - 0s - loss: 0.5015 - accuracy: 0.8014 - val_loss: 0.4518 - val_accuracy: 0.8188 - 108ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "50/50 - 0s - loss: 0.5193 - accuracy: 0.7970 - val_loss: 0.4562 - val_accuracy: 0.8081 - 94ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "50/50 - 0s - loss: 0.5092 - accuracy: 0.7994 - val_loss: 0.4462 - val_accuracy: 0.8213 - 92ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "50/50 - 0s - loss: 0.5057 - accuracy: 0.8044 - val_loss: 0.4569 - val_accuracy: 0.8119 - 98ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "50/50 - 0s - loss: 0.5181 - accuracy: 0.7897 - val_loss: 0.4572 - val_accuracy: 0.8119 - 96ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "50/50 - 0s - loss: 0.5050 - accuracy: 0.8011 - val_loss: 0.4557 - val_accuracy: 0.8144 - 104ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "50/50 - 0s - loss: 0.5009 - accuracy: 0.8059 - val_loss: 0.4574 - val_accuracy: 0.8081 - 98ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "50/50 - 0s - loss: 0.5081 - accuracy: 0.8056 - val_loss: 0.4597 - val_accuracy: 0.8087 - 96ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "50/50 - 0s - loss: 0.4893 - accuracy: 0.8059 - val_loss: 0.4552 - val_accuracy: 0.8144 - 90ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "50/50 - 0s - loss: 0.4997 - accuracy: 0.8028 - val_loss: 0.4554 - val_accuracy: 0.8125 - 90ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "50/50 - 0s - loss: 0.4917 - accuracy: 0.8117 - val_loss: 0.4543 - val_accuracy: 0.8188 - 93ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "50/50 - 0s - loss: 0.4922 - accuracy: 0.8120 - val_loss: 0.4553 - val_accuracy: 0.8163 - 97ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "50/50 - 0s - loss: 0.5038 - accuracy: 0.8062 - val_loss: 0.4491 - val_accuracy: 0.8138 - 99ms/epoch - 2ms/step\n",
      "Index(['loan_amnt', 'term', 'emp_length', 'home_ownership', 'annual_inc',\n",
      "       'purpose', 'dti', 'delinq_2yrs', 'cr_hist_age_mths', 'fico_range_low',\n",
      "       'fico_range_high', 'inq_last_6mths', 'inv_mths_since_last_delinq',\n",
      "       'inv_mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n",
      "       'revol_util', 'total_acc', 'collections_12_mths_ex_med',\n",
      "       'inv_mths_since_last_major_derog', 'application_type',\n",
      "       'annual_inc_joint', 'dti_joint', 'acc_now_delinq', 'tot_coll_amt',\n",
      "       'tot_cur_bal', 'total_rev_hi_lim', 'acc_open_past_24mths',\n",
      "       'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths',\n",
      "       'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op',\n",
      "       'inv_mo_sin_rcnt_rev_tl_op', 'inv_mo_sin_rcnt_tl', 'mort_acc',\n",
      "       'inv_mths_since_recent_bc', 'inv_mths_since_recent_bc_dlq',\n",
      "       'inv_mths_since_recent_inq', 'inv_mths_since_recent_revol_delinq',\n",
      "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
      "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
      "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
      "       'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
      "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
      "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
      "       'total_il_high_credit_limit'],\n",
      "      dtype='object')\n",
      "Epoch 1/100\n",
      "50/50 - 1s - loss: 1.8470 - accuracy: 0.2634 - val_loss: 1.5706 - val_accuracy: 0.3925 - 991ms/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "50/50 - 0s - loss: 1.6067 - accuracy: 0.3402 - val_loss: 1.4025 - val_accuracy: 0.4588 - 96ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "50/50 - 0s - loss: 1.4472 - accuracy: 0.4095 - val_loss: 1.2487 - val_accuracy: 0.5269 - 102ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "50/50 - 0s - loss: 1.3301 - accuracy: 0.4473 - val_loss: 1.1212 - val_accuracy: 0.5719 - 93ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "50/50 - 0s - loss: 1.2396 - accuracy: 0.4808 - val_loss: 1.0187 - val_accuracy: 0.5975 - 92ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "50/50 - 0s - loss: 1.1728 - accuracy: 0.5059 - val_loss: 0.9499 - val_accuracy: 0.6288 - 104ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "50/50 - 0s - loss: 1.1112 - accuracy: 0.5219 - val_loss: 0.8913 - val_accuracy: 0.6500 - 99ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "50/50 - 0s - loss: 1.0529 - accuracy: 0.5564 - val_loss: 0.8510 - val_accuracy: 0.6625 - 110ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "50/50 - 0s - loss: 1.0104 - accuracy: 0.5734 - val_loss: 0.8064 - val_accuracy: 0.6669 - 101ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "50/50 - 0s - loss: 0.9613 - accuracy: 0.5978 - val_loss: 0.7778 - val_accuracy: 0.6800 - 98ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "50/50 - 0s - loss: 0.9394 - accuracy: 0.6042 - val_loss: 0.7643 - val_accuracy: 0.6888 - 101ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "50/50 - 0s - loss: 0.9121 - accuracy: 0.6148 - val_loss: 0.7326 - val_accuracy: 0.7056 - 93ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "50/50 - 0s - loss: 0.8786 - accuracy: 0.6345 - val_loss: 0.7141 - val_accuracy: 0.7100 - 106ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "50/50 - 0s - loss: 0.8518 - accuracy: 0.6428 - val_loss: 0.6902 - val_accuracy: 0.7125 - 98ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "50/50 - 0s - loss: 0.8312 - accuracy: 0.6509 - val_loss: 0.6868 - val_accuracy: 0.7138 - 98ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "50/50 - 0s - loss: 0.8153 - accuracy: 0.6609 - val_loss: 0.6621 - val_accuracy: 0.7319 - 94ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "50/50 - 0s - loss: 0.7963 - accuracy: 0.6662 - val_loss: 0.6526 - val_accuracy: 0.7287 - 97ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "50/50 - 0s - loss: 0.7829 - accuracy: 0.6720 - val_loss: 0.6461 - val_accuracy: 0.7319 - 106ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "50/50 - 0s - loss: 0.7647 - accuracy: 0.6848 - val_loss: 0.6353 - val_accuracy: 0.7281 - 95ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "50/50 - 0s - loss: 0.7499 - accuracy: 0.6916 - val_loss: 0.6253 - val_accuracy: 0.7356 - 92ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "50/50 - 0s - loss: 0.7386 - accuracy: 0.6892 - val_loss: 0.6236 - val_accuracy: 0.7244 - 92ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "50/50 - 0s - loss: 0.7432 - accuracy: 0.6973 - val_loss: 0.6146 - val_accuracy: 0.7469 - 93ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "50/50 - 0s - loss: 0.7355 - accuracy: 0.6995 - val_loss: 0.6142 - val_accuracy: 0.7406 - 110ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "50/50 - 0s - loss: 0.7088 - accuracy: 0.7120 - val_loss: 0.6027 - val_accuracy: 0.7400 - 96ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "50/50 - 0s - loss: 0.6994 - accuracy: 0.7152 - val_loss: 0.6000 - val_accuracy: 0.7469 - 100ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "50/50 - 0s - loss: 0.7059 - accuracy: 0.7105 - val_loss: 0.5905 - val_accuracy: 0.7563 - 95ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "50/50 - 0s - loss: 0.6827 - accuracy: 0.7170 - val_loss: 0.5867 - val_accuracy: 0.7419 - 101ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "50/50 - 0s - loss: 0.6785 - accuracy: 0.7262 - val_loss: 0.5788 - val_accuracy: 0.7544 - 104ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "50/50 - 0s - loss: 0.6808 - accuracy: 0.7233 - val_loss: 0.5731 - val_accuracy: 0.7650 - 95ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "50/50 - 0s - loss: 0.6544 - accuracy: 0.7320 - val_loss: 0.5644 - val_accuracy: 0.7769 - 101ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "50/50 - 0s - loss: 0.6560 - accuracy: 0.7355 - val_loss: 0.5741 - val_accuracy: 0.7525 - 99ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "50/50 - 0s - loss: 0.6463 - accuracy: 0.7386 - val_loss: 0.5654 - val_accuracy: 0.7606 - 91ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "50/50 - 0s - loss: 0.6410 - accuracy: 0.7416 - val_loss: 0.5621 - val_accuracy: 0.7569 - 105ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "50/50 - 0s - loss: 0.6424 - accuracy: 0.7411 - val_loss: 0.5511 - val_accuracy: 0.7638 - 94ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "50/50 - 0s - loss: 0.6372 - accuracy: 0.7433 - val_loss: 0.5519 - val_accuracy: 0.7650 - 98ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "50/50 - 0s - loss: 0.6337 - accuracy: 0.7459 - val_loss: 0.5566 - val_accuracy: 0.7638 - 95ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "50/50 - 0s - loss: 0.6206 - accuracy: 0.7530 - val_loss: 0.5485 - val_accuracy: 0.7656 - 93ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "50/50 - 0s - loss: 0.6105 - accuracy: 0.7581 - val_loss: 0.5478 - val_accuracy: 0.7694 - 101ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "50/50 - 0s - loss: 0.6100 - accuracy: 0.7559 - val_loss: 0.5432 - val_accuracy: 0.7594 - 93ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "50/50 - 0s - loss: 0.6168 - accuracy: 0.7534 - val_loss: 0.5416 - val_accuracy: 0.7613 - 95ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "50/50 - 0s - loss: 0.6027 - accuracy: 0.7498 - val_loss: 0.5290 - val_accuracy: 0.7800 - 96ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "50/50 - 0s - loss: 0.6018 - accuracy: 0.7530 - val_loss: 0.5364 - val_accuracy: 0.7738 - 97ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "50/50 - 0s - loss: 0.5862 - accuracy: 0.7600 - val_loss: 0.5366 - val_accuracy: 0.7675 - 106ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "50/50 - 0s - loss: 0.5884 - accuracy: 0.7639 - val_loss: 0.5362 - val_accuracy: 0.7631 - 93ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "50/50 - 0s - loss: 0.5959 - accuracy: 0.7630 - val_loss: 0.5376 - val_accuracy: 0.7912 - 98ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "50/50 - 0s - loss: 0.5861 - accuracy: 0.7644 - val_loss: 0.5310 - val_accuracy: 0.7713 - 93ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "50/50 - 0s - loss: 0.5785 - accuracy: 0.7667 - val_loss: 0.5370 - val_accuracy: 0.7694 - 96ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "50/50 - 0s - loss: 0.5676 - accuracy: 0.7741 - val_loss: 0.5350 - val_accuracy: 0.7725 - 100ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "50/50 - 0s - loss: 0.5758 - accuracy: 0.7720 - val_loss: 0.5260 - val_accuracy: 0.7700 - 97ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "50/50 - 0s - loss: 0.5707 - accuracy: 0.7702 - val_loss: 0.5341 - val_accuracy: 0.7862 - 97ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "50/50 - 0s - loss: 0.5753 - accuracy: 0.7742 - val_loss: 0.5240 - val_accuracy: 0.7744 - 105ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "50/50 - 0s - loss: 0.5603 - accuracy: 0.7722 - val_loss: 0.5178 - val_accuracy: 0.7731 - 99ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "50/50 - 0s - loss: 0.5513 - accuracy: 0.7788 - val_loss: 0.5156 - val_accuracy: 0.7763 - 107ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "50/50 - 0s - loss: 0.5574 - accuracy: 0.7786 - val_loss: 0.5178 - val_accuracy: 0.7775 - 93ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "50/50 - 0s - loss: 0.5453 - accuracy: 0.7839 - val_loss: 0.5143 - val_accuracy: 0.7837 - 94ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "50/50 - 0s - loss: 0.5459 - accuracy: 0.7842 - val_loss: 0.5156 - val_accuracy: 0.7956 - 93ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "50/50 - 0s - loss: 0.5423 - accuracy: 0.7833 - val_loss: 0.5095 - val_accuracy: 0.7794 - 101ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "50/50 - 0s - loss: 0.5344 - accuracy: 0.7872 - val_loss: 0.5218 - val_accuracy: 0.7694 - 102ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "50/50 - 0s - loss: 0.5365 - accuracy: 0.7862 - val_loss: 0.5085 - val_accuracy: 0.7800 - 103ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "50/50 - 0s - loss: 0.5357 - accuracy: 0.7887 - val_loss: 0.5018 - val_accuracy: 0.8050 - 99ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "50/50 - 0s - loss: 0.5310 - accuracy: 0.7902 - val_loss: 0.5095 - val_accuracy: 0.7975 - 94ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "50/50 - 0s - loss: 0.5238 - accuracy: 0.7900 - val_loss: 0.5018 - val_accuracy: 0.7869 - 100ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "50/50 - 0s - loss: 0.5364 - accuracy: 0.7922 - val_loss: 0.4994 - val_accuracy: 0.7925 - 108ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "50/50 - 0s - loss: 0.5227 - accuracy: 0.7895 - val_loss: 0.5088 - val_accuracy: 0.8031 - 98ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "50/50 - 0s - loss: 0.5226 - accuracy: 0.7955 - val_loss: 0.4990 - val_accuracy: 0.7987 - 100ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "50/50 - 0s - loss: 0.5129 - accuracy: 0.7991 - val_loss: 0.5085 - val_accuracy: 0.7825 - 100ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "50/50 - 0s - loss: 0.5146 - accuracy: 0.7933 - val_loss: 0.4977 - val_accuracy: 0.7981 - 97ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "50/50 - 0s - loss: 0.5093 - accuracy: 0.8014 - val_loss: 0.5028 - val_accuracy: 0.8006 - 111ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "50/50 - 0s - loss: 0.5004 - accuracy: 0.8059 - val_loss: 0.4967 - val_accuracy: 0.7931 - 101ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "50/50 - 0s - loss: 0.4998 - accuracy: 0.8062 - val_loss: 0.5057 - val_accuracy: 0.7844 - 97ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "50/50 - 0s - loss: 0.4948 - accuracy: 0.8033 - val_loss: 0.5022 - val_accuracy: 0.7856 - 92ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "50/50 - 0s - loss: 0.4982 - accuracy: 0.8053 - val_loss: 0.4846 - val_accuracy: 0.7862 - 94ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "50/50 - 0s - loss: 0.5006 - accuracy: 0.7983 - val_loss: 0.4995 - val_accuracy: 0.7837 - 103ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "50/50 - 0s - loss: 0.5057 - accuracy: 0.8019 - val_loss: 0.4906 - val_accuracy: 0.7819 - 95ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "50/50 - 0s - loss: 0.5098 - accuracy: 0.7994 - val_loss: 0.4916 - val_accuracy: 0.8050 - 98ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "50/50 - 0s - loss: 0.4997 - accuracy: 0.8103 - val_loss: 0.4992 - val_accuracy: 0.7831 - 108ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "50/50 - 0s - loss: 0.4946 - accuracy: 0.8019 - val_loss: 0.4915 - val_accuracy: 0.8006 - 119ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "50/50 - 0s - loss: 0.4957 - accuracy: 0.8028 - val_loss: 0.4841 - val_accuracy: 0.7969 - 112ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "50/50 - 0s - loss: 0.4715 - accuracy: 0.8130 - val_loss: 0.4905 - val_accuracy: 0.7856 - 108ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "50/50 - 0s - loss: 0.4812 - accuracy: 0.8127 - val_loss: 0.4911 - val_accuracy: 0.8044 - 98ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "50/50 - 0s - loss: 0.4784 - accuracy: 0.8100 - val_loss: 0.4964 - val_accuracy: 0.7819 - 94ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "50/50 - 0s - loss: 0.4871 - accuracy: 0.8144 - val_loss: 0.5033 - val_accuracy: 0.7775 - 99ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "50/50 - 0s - loss: 0.4728 - accuracy: 0.8103 - val_loss: 0.4958 - val_accuracy: 0.7937 - 98ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "50/50 - 0s - loss: 0.4785 - accuracy: 0.8147 - val_loss: 0.4890 - val_accuracy: 0.7981 - 99ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "50/50 - 0s - loss: 0.4743 - accuracy: 0.8152 - val_loss: 0.4937 - val_accuracy: 0.8000 - 98ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "50/50 - 0s - loss: 0.4757 - accuracy: 0.8145 - val_loss: 0.5017 - val_accuracy: 0.7894 - 94ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "50/50 - 0s - loss: 0.4665 - accuracy: 0.8161 - val_loss: 0.4921 - val_accuracy: 0.8006 - 95ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "50/50 - 0s - loss: 0.4659 - accuracy: 0.8186 - val_loss: 0.5080 - val_accuracy: 0.7900 - 96ms/epoch - 2ms/step\n",
      "Index(['loan_amnt', 'term', 'emp_length', 'home_ownership', 'annual_inc',\n",
      "       'purpose', 'dti', 'delinq_2yrs', 'cr_hist_age_mths', 'fico_range_low',\n",
      "       'fico_range_high', 'inq_last_6mths', 'inv_mths_since_last_delinq',\n",
      "       'inv_mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n",
      "       'revol_util', 'total_acc', 'collections_12_mths_ex_med',\n",
      "       'inv_mths_since_last_major_derog', 'application_type',\n",
      "       'annual_inc_joint', 'dti_joint', 'acc_now_delinq', 'tot_coll_amt',\n",
      "       'tot_cur_bal', 'total_rev_hi_lim', 'acc_open_past_24mths',\n",
      "       'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths',\n",
      "       'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op',\n",
      "       'inv_mo_sin_rcnt_rev_tl_op', 'inv_mo_sin_rcnt_tl', 'mort_acc',\n",
      "       'inv_mths_since_recent_bc', 'inv_mths_since_recent_bc_dlq',\n",
      "       'inv_mths_since_recent_inq', 'inv_mths_since_recent_revol_delinq',\n",
      "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
      "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
      "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
      "       'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
      "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
      "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
      "       'total_il_high_credit_limit'],\n",
      "      dtype='object')\n",
      "Epoch 1/100\n",
      "50/50 - 1s - loss: 1.7153 - accuracy: 0.2966 - val_loss: 1.4627 - val_accuracy: 0.4200 - 989ms/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "50/50 - 0s - loss: 1.5076 - accuracy: 0.3644 - val_loss: 1.3076 - val_accuracy: 0.4400 - 105ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "50/50 - 0s - loss: 1.4034 - accuracy: 0.3975 - val_loss: 1.2160 - val_accuracy: 0.5019 - 98ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "50/50 - 0s - loss: 1.3226 - accuracy: 0.4406 - val_loss: 1.1193 - val_accuracy: 0.5475 - 108ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "50/50 - 0s - loss: 1.2381 - accuracy: 0.4792 - val_loss: 1.0281 - val_accuracy: 0.5987 - 93ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "50/50 - 0s - loss: 1.1655 - accuracy: 0.5028 - val_loss: 0.9442 - val_accuracy: 0.6419 - 92ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "50/50 - 0s - loss: 1.1216 - accuracy: 0.5177 - val_loss: 0.8940 - val_accuracy: 0.6506 - 92ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "50/50 - 0s - loss: 1.0650 - accuracy: 0.5417 - val_loss: 0.8470 - val_accuracy: 0.6900 - 90ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "50/50 - 0s - loss: 1.0165 - accuracy: 0.5625 - val_loss: 0.7935 - val_accuracy: 0.6969 - 110ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "50/50 - 0s - loss: 0.9881 - accuracy: 0.5767 - val_loss: 0.7704 - val_accuracy: 0.7056 - 100ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "50/50 - 0s - loss: 0.9421 - accuracy: 0.5966 - val_loss: 0.7379 - val_accuracy: 0.7237 - 99ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "50/50 - 0s - loss: 0.9070 - accuracy: 0.6137 - val_loss: 0.7343 - val_accuracy: 0.7275 - 95ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "50/50 - 0s - loss: 0.8863 - accuracy: 0.6197 - val_loss: 0.7057 - val_accuracy: 0.7487 - 96ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "50/50 - 0s - loss: 0.8662 - accuracy: 0.6234 - val_loss: 0.6978 - val_accuracy: 0.7406 - 105ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "50/50 - 0s - loss: 0.8424 - accuracy: 0.6388 - val_loss: 0.6811 - val_accuracy: 0.7450 - 99ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "50/50 - 0s - loss: 0.8401 - accuracy: 0.6470 - val_loss: 0.6660 - val_accuracy: 0.7475 - 104ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "50/50 - 0s - loss: 0.8196 - accuracy: 0.6525 - val_loss: 0.6629 - val_accuracy: 0.7519 - 97ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "50/50 - 0s - loss: 0.8009 - accuracy: 0.6594 - val_loss: 0.6547 - val_accuracy: 0.7519 - 98ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "50/50 - 0s - loss: 0.7799 - accuracy: 0.6706 - val_loss: 0.6490 - val_accuracy: 0.7581 - 106ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "50/50 - 0s - loss: 0.7725 - accuracy: 0.6747 - val_loss: 0.6402 - val_accuracy: 0.7644 - 96ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "50/50 - 0s - loss: 0.7625 - accuracy: 0.6712 - val_loss: 0.6325 - val_accuracy: 0.7594 - 99ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "50/50 - 0s - loss: 0.7554 - accuracy: 0.6791 - val_loss: 0.6253 - val_accuracy: 0.7656 - 94ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "50/50 - 0s - loss: 0.7405 - accuracy: 0.6847 - val_loss: 0.6233 - val_accuracy: 0.7656 - 106ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "50/50 - 0s - loss: 0.7373 - accuracy: 0.6895 - val_loss: 0.6129 - val_accuracy: 0.7669 - 105ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "50/50 - 0s - loss: 0.7346 - accuracy: 0.6955 - val_loss: 0.6116 - val_accuracy: 0.7669 - 94ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "50/50 - 0s - loss: 0.7138 - accuracy: 0.6986 - val_loss: 0.6059 - val_accuracy: 0.7769 - 98ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "50/50 - 0s - loss: 0.7220 - accuracy: 0.7031 - val_loss: 0.6042 - val_accuracy: 0.7806 - 101ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "50/50 - 0s - loss: 0.6990 - accuracy: 0.7086 - val_loss: 0.5967 - val_accuracy: 0.7800 - 99ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "50/50 - 0s - loss: 0.7015 - accuracy: 0.7106 - val_loss: 0.5948 - val_accuracy: 0.7769 - 107ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "50/50 - 0s - loss: 0.6917 - accuracy: 0.7123 - val_loss: 0.5951 - val_accuracy: 0.7844 - 96ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "50/50 - 0s - loss: 0.6852 - accuracy: 0.7148 - val_loss: 0.5954 - val_accuracy: 0.7875 - 99ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "50/50 - 0s - loss: 0.6742 - accuracy: 0.7202 - val_loss: 0.5895 - val_accuracy: 0.7744 - 96ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "50/50 - 0s - loss: 0.6763 - accuracy: 0.7228 - val_loss: 0.5826 - val_accuracy: 0.7800 - 96ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "50/50 - 0s - loss: 0.6591 - accuracy: 0.7273 - val_loss: 0.5756 - val_accuracy: 0.7831 - 106ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "50/50 - 0s - loss: 0.6599 - accuracy: 0.7286 - val_loss: 0.5679 - val_accuracy: 0.7862 - 96ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "50/50 - 0s - loss: 0.6483 - accuracy: 0.7298 - val_loss: 0.5683 - val_accuracy: 0.7875 - 100ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "50/50 - 0s - loss: 0.6510 - accuracy: 0.7358 - val_loss: 0.5735 - val_accuracy: 0.7819 - 98ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "50/50 - 0s - loss: 0.6444 - accuracy: 0.7367 - val_loss: 0.5660 - val_accuracy: 0.7931 - 98ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "50/50 - 0s - loss: 0.6341 - accuracy: 0.7394 - val_loss: 0.5704 - val_accuracy: 0.7837 - 98ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "50/50 - 0s - loss: 0.6259 - accuracy: 0.7481 - val_loss: 0.5617 - val_accuracy: 0.7981 - 93ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "50/50 - 0s - loss: 0.6210 - accuracy: 0.7452 - val_loss: 0.5545 - val_accuracy: 0.7956 - 92ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "50/50 - 0s - loss: 0.6188 - accuracy: 0.7538 - val_loss: 0.5533 - val_accuracy: 0.7906 - 96ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "50/50 - 0s - loss: 0.6215 - accuracy: 0.7506 - val_loss: 0.5557 - val_accuracy: 0.8050 - 92ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "50/50 - 0s - loss: 0.6212 - accuracy: 0.7452 - val_loss: 0.5577 - val_accuracy: 0.7962 - 111ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "50/50 - 0s - loss: 0.6066 - accuracy: 0.7600 - val_loss: 0.5541 - val_accuracy: 0.7994 - 95ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "50/50 - 0s - loss: 0.6106 - accuracy: 0.7527 - val_loss: 0.5485 - val_accuracy: 0.8000 - 98ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "50/50 - 0s - loss: 0.6055 - accuracy: 0.7577 - val_loss: 0.5495 - val_accuracy: 0.7937 - 96ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "50/50 - 0s - loss: 0.5906 - accuracy: 0.7673 - val_loss: 0.5470 - val_accuracy: 0.8000 - 95ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "50/50 - 0s - loss: 0.5690 - accuracy: 0.7767 - val_loss: 0.5371 - val_accuracy: 0.8081 - 139ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "50/50 - 0s - loss: 0.5902 - accuracy: 0.7666 - val_loss: 0.5417 - val_accuracy: 0.8031 - 96ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "50/50 - 0s - loss: 0.5922 - accuracy: 0.7638 - val_loss: 0.5334 - val_accuracy: 0.8131 - 99ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "50/50 - 0s - loss: 0.5789 - accuracy: 0.7694 - val_loss: 0.5321 - val_accuracy: 0.8069 - 95ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "50/50 - 0s - loss: 0.5779 - accuracy: 0.7722 - val_loss: 0.5282 - val_accuracy: 0.8213 - 103ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "50/50 - 0s - loss: 0.5679 - accuracy: 0.7752 - val_loss: 0.5259 - val_accuracy: 0.8069 - 99ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "50/50 - 0s - loss: 0.5748 - accuracy: 0.7772 - val_loss: 0.5282 - val_accuracy: 0.8163 - 95ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "50/50 - 0s - loss: 0.5718 - accuracy: 0.7705 - val_loss: 0.5340 - val_accuracy: 0.7969 - 95ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "50/50 - 0s - loss: 0.5515 - accuracy: 0.7788 - val_loss: 0.5255 - val_accuracy: 0.8169 - 93ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "50/50 - 0s - loss: 0.5576 - accuracy: 0.7831 - val_loss: 0.5211 - val_accuracy: 0.8125 - 93ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "50/50 - 0s - loss: 0.5510 - accuracy: 0.7769 - val_loss: 0.5181 - val_accuracy: 0.8138 - 103ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "50/50 - 0s - loss: 0.5538 - accuracy: 0.7800 - val_loss: 0.5259 - val_accuracy: 0.8138 - 98ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "50/50 - 0s - loss: 0.5537 - accuracy: 0.7811 - val_loss: 0.5268 - val_accuracy: 0.8150 - 96ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "50/50 - 0s - loss: 0.5501 - accuracy: 0.7855 - val_loss: 0.5181 - val_accuracy: 0.8188 - 99ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "50/50 - 0s - loss: 0.5528 - accuracy: 0.7784 - val_loss: 0.5269 - val_accuracy: 0.8125 - 103ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "50/50 - 0s - loss: 0.5466 - accuracy: 0.7766 - val_loss: 0.5293 - val_accuracy: 0.8119 - 97ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "50/50 - 0s - loss: 0.5364 - accuracy: 0.7850 - val_loss: 0.5241 - val_accuracy: 0.8094 - 97ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "50/50 - 0s - loss: 0.5352 - accuracy: 0.7875 - val_loss: 0.5155 - val_accuracy: 0.8075 - 96ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "50/50 - 0s - loss: 0.5195 - accuracy: 0.7945 - val_loss: 0.5164 - val_accuracy: 0.8112 - 96ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "50/50 - 0s - loss: 0.5324 - accuracy: 0.7920 - val_loss: 0.5266 - val_accuracy: 0.8044 - 93ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "50/50 - 0s - loss: 0.5392 - accuracy: 0.7912 - val_loss: 0.5129 - val_accuracy: 0.8238 - 99ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "50/50 - 0s - loss: 0.5271 - accuracy: 0.7958 - val_loss: 0.5167 - val_accuracy: 0.8138 - 98ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "50/50 - 0s - loss: 0.5282 - accuracy: 0.7905 - val_loss: 0.5235 - val_accuracy: 0.8219 - 99ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "50/50 - 0s - loss: 0.5148 - accuracy: 0.7980 - val_loss: 0.5109 - val_accuracy: 0.8175 - 100ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "50/50 - 0s - loss: 0.5213 - accuracy: 0.8044 - val_loss: 0.5120 - val_accuracy: 0.8219 - 90ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "50/50 - 0s - loss: 0.5197 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.8194 - 96ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "50/50 - 0s - loss: 0.5143 - accuracy: 0.7987 - val_loss: 0.5128 - val_accuracy: 0.8213 - 91ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "50/50 - 0s - loss: 0.5144 - accuracy: 0.7925 - val_loss: 0.5016 - val_accuracy: 0.8250 - 98ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "50/50 - 0s - loss: 0.5220 - accuracy: 0.7927 - val_loss: 0.5077 - val_accuracy: 0.8200 - 99ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "50/50 - 0s - loss: 0.5038 - accuracy: 0.8070 - val_loss: 0.5074 - val_accuracy: 0.8200 - 96ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "50/50 - 0s - loss: 0.5118 - accuracy: 0.7936 - val_loss: 0.5195 - val_accuracy: 0.8144 - 108ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "50/50 - 0s - loss: 0.5127 - accuracy: 0.7950 - val_loss: 0.5252 - val_accuracy: 0.8219 - 95ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "50/50 - 0s - loss: 0.5114 - accuracy: 0.8006 - val_loss: 0.5153 - val_accuracy: 0.8094 - 99ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "50/50 - 0s - loss: 0.4988 - accuracy: 0.8069 - val_loss: 0.5122 - val_accuracy: 0.8175 - 97ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "50/50 - 0s - loss: 0.4932 - accuracy: 0.8042 - val_loss: 0.4985 - val_accuracy: 0.8313 - 99ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "50/50 - 0s - loss: 0.4960 - accuracy: 0.8037 - val_loss: 0.5132 - val_accuracy: 0.8188 - 104ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "50/50 - 0s - loss: 0.5095 - accuracy: 0.7950 - val_loss: 0.5070 - val_accuracy: 0.8125 - 99ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "50/50 - 0s - loss: 0.4916 - accuracy: 0.8072 - val_loss: 0.5030 - val_accuracy: 0.8231 - 95ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "50/50 - 0s - loss: 0.5021 - accuracy: 0.8002 - val_loss: 0.5089 - val_accuracy: 0.8300 - 95ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "50/50 - 0s - loss: 0.4925 - accuracy: 0.8020 - val_loss: 0.4937 - val_accuracy: 0.8213 - 97ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "50/50 - 0s - loss: 0.4844 - accuracy: 0.8073 - val_loss: 0.4987 - val_accuracy: 0.8288 - 105ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "50/50 - 0s - loss: 0.4841 - accuracy: 0.8080 - val_loss: 0.5137 - val_accuracy: 0.8219 - 89ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "50/50 - 0s - loss: 0.4930 - accuracy: 0.8016 - val_loss: 0.4964 - val_accuracy: 0.8294 - 90ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "50/50 - 0s - loss: 0.4898 - accuracy: 0.8084 - val_loss: 0.4889 - val_accuracy: 0.8281 - 93ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "50/50 - 0s - loss: 0.4938 - accuracy: 0.8106 - val_loss: 0.5079 - val_accuracy: 0.8238 - 92ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "50/50 - 0s - loss: 0.4733 - accuracy: 0.8169 - val_loss: 0.4911 - val_accuracy: 0.8281 - 106ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "50/50 - 0s - loss: 0.4794 - accuracy: 0.8083 - val_loss: 0.5022 - val_accuracy: 0.8219 - 100ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "50/50 - 0s - loss: 0.4957 - accuracy: 0.8092 - val_loss: 0.4979 - val_accuracy: 0.8294 - 98ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "50/50 - 0s - loss: 0.4796 - accuracy: 0.8170 - val_loss: 0.4985 - val_accuracy: 0.8244 - 99ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "50/50 - 0s - loss: 0.4685 - accuracy: 0.8155 - val_loss: 0.4963 - val_accuracy: 0.8288 - 98ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "50/50 - 0s - loss: 0.4606 - accuracy: 0.8220 - val_loss: 0.5116 - val_accuracy: 0.8163 - 104ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "50/50 - 0s - loss: 0.4768 - accuracy: 0.8156 - val_loss: 0.4979 - val_accuracy: 0.8219 - 97ms/epoch - 2ms/step\n",
      "Index(['loan_amnt', 'term', 'emp_length', 'home_ownership', 'annual_inc',\n",
      "       'purpose', 'dti', 'delinq_2yrs', 'cr_hist_age_mths', 'fico_range_low',\n",
      "       'fico_range_high', 'inq_last_6mths', 'inv_mths_since_last_delinq',\n",
      "       'inv_mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n",
      "       'revol_util', 'total_acc', 'collections_12_mths_ex_med',\n",
      "       'inv_mths_since_last_major_derog', 'application_type',\n",
      "       'annual_inc_joint', 'dti_joint', 'acc_now_delinq', 'tot_coll_amt',\n",
      "       'tot_cur_bal', 'total_rev_hi_lim', 'acc_open_past_24mths',\n",
      "       'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths',\n",
      "       'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op',\n",
      "       'inv_mo_sin_rcnt_rev_tl_op', 'inv_mo_sin_rcnt_tl', 'mort_acc',\n",
      "       'inv_mths_since_recent_bc', 'inv_mths_since_recent_bc_dlq',\n",
      "       'inv_mths_since_recent_inq', 'inv_mths_since_recent_revol_delinq',\n",
      "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
      "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
      "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
      "       'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
      "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
      "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
      "       'total_il_high_credit_limit'],\n",
      "      dtype='object')\n",
      "Epoch 1/100\n",
      "50/50 - 1s - loss: 1.8872 - accuracy: 0.2686 - val_loss: 1.5729 - val_accuracy: 0.4206 - 960ms/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "50/50 - 0s - loss: 1.6079 - accuracy: 0.3595 - val_loss: 1.3793 - val_accuracy: 0.4650 - 101ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "50/50 - 0s - loss: 1.4866 - accuracy: 0.4075 - val_loss: 1.2566 - val_accuracy: 0.5006 - 108ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "50/50 - 0s - loss: 1.3791 - accuracy: 0.4416 - val_loss: 1.1600 - val_accuracy: 0.5325 - 99ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "50/50 - 0s - loss: 1.2782 - accuracy: 0.4739 - val_loss: 1.0684 - val_accuracy: 0.5763 - 102ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "50/50 - 0s - loss: 1.2217 - accuracy: 0.4925 - val_loss: 1.0001 - val_accuracy: 0.6081 - 100ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "50/50 - 0s - loss: 1.1479 - accuracy: 0.5170 - val_loss: 0.9455 - val_accuracy: 0.6338 - 99ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "50/50 - 0s - loss: 1.0790 - accuracy: 0.5455 - val_loss: 0.8905 - val_accuracy: 0.6525 - 101ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "50/50 - 0s - loss: 1.0424 - accuracy: 0.5680 - val_loss: 0.8572 - val_accuracy: 0.6612 - 101ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "50/50 - 0s - loss: 0.9989 - accuracy: 0.5820 - val_loss: 0.8159 - val_accuracy: 0.6731 - 99ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "50/50 - 0s - loss: 0.9673 - accuracy: 0.6000 - val_loss: 0.7889 - val_accuracy: 0.6781 - 100ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "50/50 - 0s - loss: 0.9326 - accuracy: 0.6111 - val_loss: 0.7698 - val_accuracy: 0.6956 - 98ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "50/50 - 0s - loss: 0.9044 - accuracy: 0.6122 - val_loss: 0.7381 - val_accuracy: 0.7219 - 98ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "50/50 - 0s - loss: 0.8933 - accuracy: 0.6264 - val_loss: 0.7215 - val_accuracy: 0.7262 - 92ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "50/50 - 0s - loss: 0.8593 - accuracy: 0.6409 - val_loss: 0.7121 - val_accuracy: 0.7275 - 91ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "50/50 - 0s - loss: 0.8578 - accuracy: 0.6488 - val_loss: 0.6993 - val_accuracy: 0.7194 - 94ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "50/50 - 0s - loss: 0.8308 - accuracy: 0.6516 - val_loss: 0.6779 - val_accuracy: 0.7306 - 100ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "50/50 - 0s - loss: 0.8093 - accuracy: 0.6559 - val_loss: 0.6653 - val_accuracy: 0.7331 - 106ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "50/50 - 0s - loss: 0.7909 - accuracy: 0.6722 - val_loss: 0.6571 - val_accuracy: 0.7419 - 96ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "50/50 - 0s - loss: 0.7861 - accuracy: 0.6644 - val_loss: 0.6553 - val_accuracy: 0.7431 - 101ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "50/50 - 0s - loss: 0.7739 - accuracy: 0.6758 - val_loss: 0.6363 - val_accuracy: 0.7494 - 96ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "50/50 - 0s - loss: 0.7592 - accuracy: 0.6812 - val_loss: 0.6381 - val_accuracy: 0.7450 - 95ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "50/50 - 0s - loss: 0.7574 - accuracy: 0.6919 - val_loss: 0.6294 - val_accuracy: 0.7487 - 102ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "50/50 - 0s - loss: 0.7439 - accuracy: 0.6998 - val_loss: 0.6246 - val_accuracy: 0.7487 - 97ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "50/50 - 0s - loss: 0.7365 - accuracy: 0.6942 - val_loss: 0.6163 - val_accuracy: 0.7544 - 98ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "50/50 - 0s - loss: 0.7144 - accuracy: 0.7066 - val_loss: 0.6013 - val_accuracy: 0.7550 - 98ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "50/50 - 0s - loss: 0.7179 - accuracy: 0.6995 - val_loss: 0.5948 - val_accuracy: 0.7619 - 96ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "50/50 - 0s - loss: 0.7130 - accuracy: 0.7053 - val_loss: 0.6007 - val_accuracy: 0.7556 - 104ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "50/50 - 0s - loss: 0.6970 - accuracy: 0.7198 - val_loss: 0.5889 - val_accuracy: 0.7594 - 99ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "50/50 - 0s - loss: 0.6997 - accuracy: 0.7116 - val_loss: 0.5932 - val_accuracy: 0.7625 - 96ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "50/50 - 0s - loss: 0.6825 - accuracy: 0.7189 - val_loss: 0.5758 - val_accuracy: 0.7738 - 93ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "50/50 - 0s - loss: 0.6805 - accuracy: 0.7181 - val_loss: 0.5824 - val_accuracy: 0.7656 - 93ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "50/50 - 0s - loss: 0.6693 - accuracy: 0.7234 - val_loss: 0.5738 - val_accuracy: 0.7631 - 98ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "50/50 - 0s - loss: 0.6612 - accuracy: 0.7331 - val_loss: 0.5700 - val_accuracy: 0.7644 - 102ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "50/50 - 0s - loss: 0.6433 - accuracy: 0.7300 - val_loss: 0.5656 - val_accuracy: 0.7700 - 98ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "50/50 - 0s - loss: 0.6445 - accuracy: 0.7359 - val_loss: 0.5674 - val_accuracy: 0.7688 - 101ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "50/50 - 0s - loss: 0.6280 - accuracy: 0.7456 - val_loss: 0.5616 - val_accuracy: 0.7638 - 102ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "50/50 - 0s - loss: 0.6217 - accuracy: 0.7497 - val_loss: 0.5600 - val_accuracy: 0.7644 - 103ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "50/50 - 0s - loss: 0.6340 - accuracy: 0.7408 - val_loss: 0.5551 - val_accuracy: 0.7731 - 98ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "50/50 - 0s - loss: 0.6303 - accuracy: 0.7437 - val_loss: 0.5495 - val_accuracy: 0.7763 - 97ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "50/50 - 0s - loss: 0.6105 - accuracy: 0.7534 - val_loss: 0.5560 - val_accuracy: 0.7606 - 96ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "50/50 - 0s - loss: 0.6022 - accuracy: 0.7539 - val_loss: 0.5486 - val_accuracy: 0.7700 - 99ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "50/50 - 0s - loss: 0.6193 - accuracy: 0.7520 - val_loss: 0.5491 - val_accuracy: 0.7656 - 101ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "50/50 - 0s - loss: 0.6061 - accuracy: 0.7544 - val_loss: 0.5462 - val_accuracy: 0.7763 - 102ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "50/50 - 0s - loss: 0.6102 - accuracy: 0.7520 - val_loss: 0.5490 - val_accuracy: 0.7694 - 94ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "50/50 - 0s - loss: 0.5963 - accuracy: 0.7678 - val_loss: 0.5434 - val_accuracy: 0.7700 - 94ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "50/50 - 0s - loss: 0.5818 - accuracy: 0.7638 - val_loss: 0.5344 - val_accuracy: 0.7800 - 99ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "50/50 - 0s - loss: 0.5821 - accuracy: 0.7673 - val_loss: 0.5319 - val_accuracy: 0.7850 - 96ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "50/50 - 0s - loss: 0.5773 - accuracy: 0.7689 - val_loss: 0.5268 - val_accuracy: 0.7788 - 93ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "50/50 - 0s - loss: 0.5723 - accuracy: 0.7702 - val_loss: 0.5374 - val_accuracy: 0.7844 - 95ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "50/50 - 0s - loss: 0.5719 - accuracy: 0.7752 - val_loss: 0.5269 - val_accuracy: 0.7837 - 104ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "50/50 - 0s - loss: 0.5608 - accuracy: 0.7730 - val_loss: 0.5221 - val_accuracy: 0.7881 - 96ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "50/50 - 0s - loss: 0.5601 - accuracy: 0.7831 - val_loss: 0.5182 - val_accuracy: 0.7837 - 106ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "50/50 - 0s - loss: 0.5514 - accuracy: 0.7805 - val_loss: 0.5237 - val_accuracy: 0.7925 - 100ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "50/50 - 0s - loss: 0.5474 - accuracy: 0.7736 - val_loss: 0.5310 - val_accuracy: 0.7831 - 102ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "50/50 - 0s - loss: 0.5630 - accuracy: 0.7763 - val_loss: 0.5132 - val_accuracy: 0.7944 - 96ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "50/50 - 0s - loss: 0.5418 - accuracy: 0.7823 - val_loss: 0.5153 - val_accuracy: 0.7912 - 93ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "50/50 - 0s - loss: 0.5424 - accuracy: 0.7862 - val_loss: 0.5165 - val_accuracy: 0.8019 - 102ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "50/50 - 0s - loss: 0.5329 - accuracy: 0.7877 - val_loss: 0.5139 - val_accuracy: 0.7906 - 96ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "50/50 - 0s - loss: 0.5473 - accuracy: 0.7884 - val_loss: 0.5125 - val_accuracy: 0.7887 - 98ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "50/50 - 0s - loss: 0.5418 - accuracy: 0.7806 - val_loss: 0.5155 - val_accuracy: 0.7862 - 98ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "50/50 - 0s - loss: 0.5425 - accuracy: 0.7817 - val_loss: 0.5151 - val_accuracy: 0.7887 - 97ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "50/50 - 0s - loss: 0.5474 - accuracy: 0.7814 - val_loss: 0.5163 - val_accuracy: 0.7931 - 107ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "50/50 - 0s - loss: 0.5411 - accuracy: 0.7902 - val_loss: 0.5141 - val_accuracy: 0.7856 - 94ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "50/50 - 0s - loss: 0.5270 - accuracy: 0.7869 - val_loss: 0.5071 - val_accuracy: 0.7919 - 93ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "50/50 - 0s - loss: 0.5308 - accuracy: 0.7894 - val_loss: 0.5032 - val_accuracy: 0.8006 - 93ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "50/50 - 0s - loss: 0.5195 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7894 - 92ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "50/50 - 0s - loss: 0.5208 - accuracy: 0.7878 - val_loss: 0.5075 - val_accuracy: 0.7944 - 111ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "50/50 - 0s - loss: 0.5174 - accuracy: 0.7981 - val_loss: 0.5092 - val_accuracy: 0.7837 - 97ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "50/50 - 0s - loss: 0.5155 - accuracy: 0.7975 - val_loss: 0.5006 - val_accuracy: 0.7931 - 99ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "50/50 - 0s - loss: 0.5090 - accuracy: 0.7995 - val_loss: 0.4946 - val_accuracy: 0.7919 - 101ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "50/50 - 0s - loss: 0.5075 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7894 - 100ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "50/50 - 0s - loss: 0.5077 - accuracy: 0.8028 - val_loss: 0.5059 - val_accuracy: 0.7944 - 105ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "50/50 - 0s - loss: 0.5012 - accuracy: 0.8033 - val_loss: 0.4967 - val_accuracy: 0.7987 - 100ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "50/50 - 0s - loss: 0.4970 - accuracy: 0.8033 - val_loss: 0.5097 - val_accuracy: 0.7962 - 95ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "50/50 - 0s - loss: 0.5166 - accuracy: 0.7997 - val_loss: 0.5041 - val_accuracy: 0.8012 - 91ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "50/50 - 0s - loss: 0.5063 - accuracy: 0.8042 - val_loss: 0.4969 - val_accuracy: 0.8031 - 99ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "50/50 - 0s - loss: 0.5088 - accuracy: 0.7967 - val_loss: 0.5038 - val_accuracy: 0.8000 - 107ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "50/50 - 0s - loss: 0.5025 - accuracy: 0.7972 - val_loss: 0.4983 - val_accuracy: 0.8037 - 97ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "50/50 - 0s - loss: 0.5026 - accuracy: 0.7991 - val_loss: 0.4923 - val_accuracy: 0.7987 - 98ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "50/50 - 0s - loss: 0.4959 - accuracy: 0.8123 - val_loss: 0.4962 - val_accuracy: 0.7900 - 92ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "50/50 - 0s - loss: 0.4833 - accuracy: 0.8161 - val_loss: 0.5078 - val_accuracy: 0.7931 - 92ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "50/50 - 0s - loss: 0.4867 - accuracy: 0.8052 - val_loss: 0.5060 - val_accuracy: 0.8031 - 95ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "50/50 - 0s - loss: 0.4808 - accuracy: 0.8148 - val_loss: 0.4991 - val_accuracy: 0.8056 - 92ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "50/50 - 0s - loss: 0.4871 - accuracy: 0.8034 - val_loss: 0.4933 - val_accuracy: 0.7981 - 101ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "50/50 - 0s - loss: 0.4773 - accuracy: 0.8067 - val_loss: 0.4929 - val_accuracy: 0.7981 - 98ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "50/50 - 0s - loss: 0.4754 - accuracy: 0.8105 - val_loss: 0.5016 - val_accuracy: 0.7994 - 98ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "50/50 - 0s - loss: 0.4779 - accuracy: 0.8133 - val_loss: 0.5026 - val_accuracy: 0.8000 - 104ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "50/50 - 0s - loss: 0.4917 - accuracy: 0.8136 - val_loss: 0.5042 - val_accuracy: 0.7969 - 100ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "50/50 - 0s - loss: 0.4823 - accuracy: 0.8081 - val_loss: 0.5007 - val_accuracy: 0.7919 - 97ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Encode loan grades as integers\n",
    "grade_encoder = {\n",
    "    \"A\": 0,\n",
    "    \"B\": 1,\n",
    "    \"C\": 2,\n",
    "    \"D\": 3,\n",
    "    \"E\": 4,\n",
    "    \"F\": 5,\n",
    "    \"G\": 6,\n",
    "}\n",
    "train[\"grade_encoded\"] = train[\"grade\"].apply(lambda x: grade_encoder[x])\n",
    "test[\"grade_encoded\"] = test[\"grade\"].apply(lambda x: grade_encoder[x])\n",
    "\n",
    "# Run the pipeline with cross-validation\n",
    "nn_history_list, nn_model_list, nn_transformer_list = run_pipeline_cv_nn(\n",
    "    train,\n",
    "    onehot_cols,\n",
    "    ordinal_cols,\n",
    "    batch_size=128,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def run_pipeline_cv_svm(\n",
    "    data,\n",
    "    onehot_cols,\n",
    "    ordinal_cols,\n",
    "):\n",
    "    X = data.drop(columns=[\"issue_d\", \"date\", \"grade\", \"grade_encoded\", \"sub_grade\", \"recovered_percentage\", \"expected_return\"])\n",
    "    y = data[\"grade_encoded\"]\n",
    "\n",
    "    transformer = DataFrameMapper(\n",
    "        [\n",
    "            (onehot_cols, OneHotEncoder(drop=\"if_binary\", handle_unknown=\"error\")),\n",
    "            (\n",
    "                list(ordinal_cols.keys()),\n",
    "                OrdinalEncoder(categories=list(ordinal_cols.values())),\n",
    "            ),\n",
    "        ],\n",
    "        default=StandardScaler(),\n",
    "    )\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    history_list = []\n",
    "    model_list = []\n",
    "    transformer_list = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        print(\"before trans: \")\n",
    "        print(X_train.shape)\n",
    "        print(X_valid.shape)\n",
    "        X_train = transformer.fit_transform(X_train)\n",
    "        X_valid = transformer.transform(X_valid)\n",
    "\n",
    "        print(\"after trans: \")\n",
    "        print(X_train.shape)\n",
    "        print(X_valid.shape)\n",
    "\n",
    "        # Define the parameter grid to search\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'gamma': [0.01, 0.1, 1]\n",
    "        }\n",
    "\n",
    "        # Define the SVM model\n",
    "        svm = SVC(kernel='linear')\n",
    "\n",
    "        # Use GridSearchCV to search for the best hyperparameters\n",
    "        grid_search = GridSearchCV(svm, param_grid, cv=5, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Print the best hyperparameters and their corresponding score\n",
    "        print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "        print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "        history_list.append(None)\n",
    "        model_list.append(grid_search.best_estimator_)\n",
    "        transformer_list.append(transformer)\n",
    "\n",
    "    return history_list, model_list, transformer_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before trans: \n",
      "(6400, 65)\n",
      "(1600, 65)\n",
      "after trans: \n",
      "(6400, 79)\n",
      "(1600, 79)\n",
      "Best hyperparameters: {'C': 1, 'gamma': 0.01}\n",
      "Best score: 0.7753125\n",
      "before trans: \n",
      "(6400, 65)\n",
      "(1600, 65)\n",
      "after trans: \n",
      "(6400, 79)\n",
      "(1600, 79)\n",
      "Best hyperparameters: {'C': 1, 'gamma': 0.01}\n",
      "Best score: 0.77515625\n",
      "before trans: \n",
      "(6400, 65)\n",
      "(1600, 65)\n",
      "after trans: \n",
      "(6400, 79)\n",
      "(1600, 79)\n",
      "Best hyperparameters: {'C': 1, 'gamma': 0.01}\n",
      "Best score: 0.780625\n",
      "before trans: \n",
      "(6400, 65)\n",
      "(1600, 65)\n",
      "after trans: \n",
      "(6400, 79)\n",
      "(1600, 79)\n",
      "Best hyperparameters: {'C': 1, 'gamma': 0.01}\n",
      "Best score: 0.775625\n",
      "before trans: \n",
      "(6400, 65)\n",
      "(1600, 65)\n",
      "after trans: \n",
      "(6400, 79)\n",
      "(1600, 79)\n",
      "Best hyperparameters: {'C': 1, 'gamma': 0.01}\n",
      "Best score: 0.77359375\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline with cross-validation\n",
    "svm_history_list, svm_model_list, svm_transformer_list = run_pipeline_cv_svm(\n",
    "    train,\n",
    "    onehot_cols,\n",
    "    ordinal_cols,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def run_pipeline_cv_rf(data, onehot_cols, ordinal_cols):\n",
    "    X = data.drop(columns=[\"issue_d\", \"date\", \"grade\", \"grade_encoded\", \"sub_grade\", \"recovered_percentage\", \"expected_return\"])\n",
    "    y = data[\"grade_encoded\"]\n",
    "\n",
    "    transformer = DataFrameMapper(\n",
    "        [\n",
    "            (onehot_cols, OneHotEncoder(drop=\"if_binary\", handle_unknown=\"error\")),\n",
    "            (\n",
    "                list(ordinal_cols.keys()),\n",
    "                OrdinalEncoder(categories=list(ordinal_cols.values())),\n",
    "            ),\n",
    "        ],\n",
    "        default=StandardScaler(),\n",
    "    )\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    history_list = []\n",
    "    model_list = []\n",
    "    transformer_list = []\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "    }\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        X_train = transformer.fit_transform(X_train)\n",
    "        X_valid = transformer.transform(X_valid)\n",
    "\n",
    "        # Define the model architecture\n",
    "        model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "        # Use GridSearchCV to search over a grid of hyperparameters\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = grid_search.predict(X_valid)\n",
    "        accuracy = accuracy_score(y_valid, y_pred)\n",
    "        print(f\"Accuracy on validation set: {accuracy:.4f}\")\n",
    "\n",
    "        history_list.append({\"accuracy\": accuracy})\n",
    "        model_list.append(grid_search)\n",
    "        transformer_list.append(transformer)\n",
    "\n",
    "    return history_list, model_list, transformer_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.6644\n",
      "Accuracy on validation set: 0.6750\n",
      "Accuracy on validation set: 0.6656\n",
      "Accuracy on validation set: 0.6481\n",
      "Accuracy on validation set: 0.6569\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline with cross-validation\n",
    "rf_history_list, rf_model_list, rf_transformer_list = run_pipeline_cv_rf(\n",
    "    train,\n",
    "    onehot_cols,\n",
    "    ordinal_cols,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 943us/step\n",
      "63/63 [==============================] - 0s 930us/step\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 915us/step\n",
      "63/63 [==============================] - 0s 868us/step\n",
      "Ensemble accuracy: 0.8175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d5/hpc31dsx59l4rfyrs6m6yvp00000gn/T/ipykernel_89623/3564465338.py:45: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  final_predictions = mode(class_predictions_array, axis=0).mode[0]\n"
     ]
    }
   ],
   "source": [
    "# Load the test set and extract the true labels\n",
    "X_test = test.drop(columns=[\"issue_d\", \"date\", \"grade\", \"grade_encoded\", \"sub_grade\", \"recovered_percentage\", \"expected_return\"])\n",
    "y_test = test[\"grade_encoded\"]\n",
    "\n",
    "# Make predictions using the ensemble model\n",
    "predictions_list_nn = []\n",
    "predictions_list = []\n",
    "\n",
    "for i in range(len(nn_model_list)):\n",
    "    transformer = nn_transformer_list[i]\n",
    "    model = nn_model_list[i]\n",
    "\n",
    "    X_test_transformed = transformer.transform(X_test)\n",
    "    y_pred = model.predict(X_test_transformed)\n",
    "    predictions_list_nn.append(y_pred)\n",
    "\n",
    "for i in range(len(svm_model_list)):\n",
    "    transformer = svm_transformer_list[i]\n",
    "    model = svm_model_list[i]\n",
    "\n",
    "    X_test_transformed = transformer.transform(X_test)\n",
    "    y_pred = model.predict(X_test_transformed)\n",
    "    predictions_list.append(y_pred)\n",
    "\n",
    "for i in range(len(rf_model_list)):\n",
    "    transformer = rf_transformer_list[i]\n",
    "    model = rf_model_list[i]\n",
    "\n",
    "    X_test_transformed = transformer.transform(X_test)\n",
    "    y_pred = model.predict(X_test_transformed)\n",
    "    predictions_list.append(y_pred)\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Convert the predictions to class labels\n",
    "class_predictions_list = [np.argmax(predictions, axis=1) for predictions in predictions_list_nn]\n",
    "\n",
    "for predictions in predictions_list:\n",
    "    class_predictions_list.append(predictions)\n",
    "\n",
    "# Combine the predictions from each model\n",
    "class_predictions_array = np.array(class_predictions_list)\n",
    "\n",
    "# Take the majority vote for each test sample\n",
    "final_predictions = mode(class_predictions_array, axis=0).mode[0]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "\n",
    "print(\"Ensemble accuracy:\", accuracy)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of ensemble model on test set: 0.8153\n",
      "Recall of ensemble model on test set: 0.8175\n",
      "F1-score of ensemble model on test set: 0.8148\n"
     ]
    }
   ],
   "source": [
    "# Compute precision, recall, and F1-score of the ensemble model\n",
    "precision = precision_score(y_test, final_predictions, average=\"weighted\", zero_division=0)\n",
    "recall = recall_score(y_test, final_predictions, average=\"weighted\", zero_division=0)\n",
    "f1 = f1_score(y_test, final_predictions, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(f\"Precision of ensemble model on test set: {precision:.4f}\")\n",
    "print(f\"Recall of ensemble model on test set: {recall:.4f}\")\n",
    "print(f\"F1-score of ensemble model on test set: {f1:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the confusion matrix of the ensemble model\n",
    "confusion = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "sns.heatmap(confusion, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 17:15:17.823592: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:17.842274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:17.860561: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:18.095756: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:18.140678: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:18.180448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_loan_grade_model_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_loan_grade_model_0/assets\n",
      "2023-04-26 17:15:18.843711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:18.860389: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:18.877128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:19.083779: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:19.119491: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:19.159608: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_loan_grade_model_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_loan_grade_model_1/assets\n",
      "2023-04-26 17:15:19.773573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:19.789158: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:19.804882: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:20.008409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:20.049887: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:20.087953: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_loan_grade_model_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_loan_grade_model_2/assets\n",
      "2023-04-26 17:15:20.748726: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:20.763148: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:20.777257: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:20.959112: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:20.996838: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:21.031545: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_loan_grade_model_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_loan_grade_model_3/assets\n",
      "2023-04-26 17:15:21.672438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:21.690459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:21.706223: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:21.913488: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:21.961212: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-26 17:15:22.003604: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_loan_grade_model_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_loan_grade_model_4/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": "['rf_classification_transformer.joblib']"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the neural network models and data transformers\n",
    "for i, model in enumerate(nn_model_list):\n",
    "    model.save(f\"nn_loan_grade_model_{i}\")\n",
    "joblib.dump(nn_transformer_list, \"nn_classification_transformer.joblib\")\n",
    "\n",
    "# Save the SVM models and data transformers\n",
    "for i, model in enumerate(svm_model_list):\n",
    "    joblib.dump(model, f\"svm_loan_grade_risk_model_{i}.joblib\")\n",
    "joblib.dump(svm_transformer_list, \"svm_classification_transformer.joblib\")\n",
    "\n",
    "# Save the RF models and data transformers\n",
    "for i, model in enumerate(rf_model_list):\n",
    "    joblib.dump(model, f\"rf_loan_grade_risk_model_{i}.joblib\")\n",
    "joblib.dump(rf_transformer_list, \"rf_classification_transformer.joblib\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
